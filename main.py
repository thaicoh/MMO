import pyautogui
import time
import cv2
import numpy as np
import pytesseract
from PIL import Image

# Ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n ƒë·∫øn tesseract.exe n·∫øu c·∫ßn
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

moTaVideo = "#ShopeeCreator #ShopeeStyle #ShopeeVideo #LuotVuiMuaLien #VideohangDoiSong #VideohangTieuDung #VideohangGiaDung X·ªãn l·∫Ømm üòª"
linkSP = ""

def click_nut_dang_video(vitri_nut=(2540, 1637), delay=0.5, timeout=2, threshold=0.95):
    # X√°c ƒë·ªãnh v√πng ·∫£nh quanh n√∫t
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("truoc_click.png", region=vung_nut)
    
    print(f"ƒêang click t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click, ch·ªù giao di·ªán ph·∫£n h·ªìi...")

    time.sleep(timeout)  # ch·ªù ph·∫£n h·ªìi giao di·ªán

    # Ch·ª•p l·∫°i ·∫£nh sau khi click
    pyautogui.screenshot("sau_click.png", region=vung_nut)

    # So s√°nh ·∫£nh tr∆∞·ªõc & sau ƒë·ªÉ ki·ªÉm tra n√∫t c√≤n kh√¥ng
    img1 = cv2.imread("truoc_click.png")
    img2 = cv2.imread("sau_click.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa tr∆∞·ªõc & sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ N√∫t ƒë√£ bi·∫øn m·∫•t ho·∫∑c thay ƒë·ªïi ‚Üí Click TH√ÄNH C√îNG.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n ‚Üí Click c√≥ th·ªÉ KH√îNG th√†nh c√¥ng.")
        return False
    
def click_nut_thu_vien(vitri_nut=(2535, 1392), delay=0.5, timeout=1, threshold=0.95):
    # üì∏ V√πng ch·ª•p ·∫£nh ƒë·ªÉ so s√°nh to√†n b·ªô giao di·ªán (gi·ªëng nh∆∞ h√†m ·∫£nh b√¨a)
    vung_so_sanh = (1911, 117, 2686 - 1911, 1687 - 117)

    # V√πng n√∫t gi·ªØ nguy√™n
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("thu_vien_truoc.png", region=vung_so_sanh)

    print(f"Click n√∫t Th∆∞ vi·ªán t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p l·∫°i sau khi click
    pyautogui.screenshot("thu_vien_sau.png", region=vung_so_sanh)

    img1 = cv2.imread("thu_vien_truoc.png")
    img2 = cv2.imread("thu_vien_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click n√∫t Th∆∞ vi·ªán th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

def click_chon_video(delay=0.5, timeout=3, threshold=0.95):
    global vitri_chon_video, so_lan_click_video, cuon_chuot_y
    time.sleep(1)

    # L·∫ßn ƒë·∫ßu c·ªë ƒë·ªãnh v·ªã tr√≠ n√∫t
    if so_lan_click_video == 0:
        vitri_nut = (2001, 415)
    else:
        vitri_nut = tuple(vitri_chon_video)

    # V√πng ƒë·ªÉ x√°c ƒë·ªãnh n√∫t (v·∫´n gi·ªØ nguy√™n)
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # üì∏ V√πng ch·ª•p ·∫£nh m·ªü r·ªông ƒë·ªÉ so s√°nh
    vung_so_sanh = (1911, 117, 2686 - 1911, 1687 - 117)

    pyautogui.screenshot("video_truoc.png", region=vung_so_sanh)
    print(f"Click ch·ªçn video t·∫°i {vitri_nut} (l·∫ßn th·ª© {so_lan_click_video + 1}) sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    pyautogui.screenshot("video_sau.png", region=vung_so_sanh)
    img1 = cv2.imread("video_truoc.png")
    img2 = cv2.imread("video_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click ch·ªçn video th√†nh c√¥ng.")

        # C·∫≠p nh·∫≠t v·ªã tr√≠ cho l·∫ßn k·∫ø ti·∫øp
        so_lan_click_video += 1

        if so_lan_click_video == 1:
            vitri_chon_video = [2201, 415]
        elif so_lan_click_video % 4 != 0:
            vitri_chon_video[0] += 200
        else:
            vitri_chon_video = [2001, 415]
            cuon_chuot_y += 180

        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

def click_nut_tiep_theo(vitri_nut=(2555, 1605), delay=0.5, timeout=2, threshold=0.95):
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("tiep_theo_truoc.png", region=vung_nut)

    print(f"Click n√∫t Ti·∫øp theo t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p l·∫°i sau khi click
    pyautogui.screenshot("tiep_theo_sau.png", region=vung_nut)

    img1 = cv2.imread("tiep_theo_truoc.png")
    img2 = cv2.imread("tiep_theo_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click n√∫t Ti·∫øp theo th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

import pyautogui
import cv2
import time

def click_nut_chon_anh_bia(vitri_nut=(2041, 510), delay=0.5, timeout=2, threshold=0.95):
    # üì∏ V√πng so s√°nh ·∫£nh c·ªë ƒë·ªãnh
    vung_so_sanh = (1911, 117, 2686 - 1911, 1687 - 117)

    # V√πng n√∫t (v·∫´n m·ªü r·ªông nh∆∞ c≈©)
    width = 250
    height = 150
    vung_nut = (
        vitri_nut[0] - width // 2,
        vitri_nut[1] - height // 2,
        width,
        height
    )

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("anh_bia_truoc.png", region=vung_so_sanh)

    print(f"Click n√∫t ch·ªçn ·∫£nh b√¨a t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p ·∫£nh sau khi click
    pyautogui.screenshot("anh_bia_sau.png", region=vung_so_sanh)

    # So s√°nh ·∫£nh
    img1 = cv2.imread("anh_bia_truoc.png")
    img2 = cv2.imread("anh_bia_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click ch·ªçn ·∫£nh b√¨a th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

def chup_anh_so_video(filename="anhSoCuaVideo.png"):
    # T·ªça ƒë·ªô g√≥c tr√™n b√™n tr√°i
    x1, y1 = 2231, 766
    # T·ªça ƒë·ªô g√≥c d∆∞·ªõi b√™n ph·∫£i (v√≠ d·ª•)
    x2, y2 = 2369, 880

    width = x2 - x1
    height = y2 - y1

    # Ch·ª•p ·∫£nh v√πng x√°c ƒë·ªãnh
    screenshot = pyautogui.screenshot(region=(x1, y1, width, height))
    screenshot.save(filename)
    print(f"‚úÖ ƒê√£ l∆∞u ·∫£nh v√†o: {filename}")

def nhan_dien_so_tu_anh(duong_dan_anh):
    try:
        # 1. ƒê·ªçc ·∫£nh
        img = cv2.imread(duong_dan_anh)

        # 2. C·∫Øt 1% m√©p tr√°i/ph·∫£i
        h, w = img.shape[:2]
        left = int(w * 0.01)
        right = int(w * 0.99)
        img = img[:, left:right]

        # 3. Th√™m padding tr·∫Øng
        padding = 50
        img = cv2.copyMakeBorder(
            img, padding, padding, padding, padding,
            cv2.BORDER_CONSTANT, value=[255, 255, 255]
        )

        # 4. Chuy·ªÉn sang x√°m
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # 5. Nh·ªã ph√¢n h√≥a
        _, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)

        # 6. Lo·∫°i ƒë·ªëm nh·ªè
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        for cnt in contours:
            if cv2.contourArea(cnt) < 30:
                cv2.drawContours(thresh, [cnt], -1, 0, -1)

        # 7. L√†m ƒë·∫ßy s·ªë
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)

        # 8. ƒê·∫£o m√†u
        inverted = cv2.bitwise_not(closed)

        # 9. Ph√≥ng to ·∫£nh
        scale_up = cv2.resize(inverted, None, fx=3, fy=3, interpolation=cv2.INTER_LINEAR)

        # 10. L∆∞u ·∫£nh sau x·ª≠ l√Ω (tu·ª≥ ch·ªçn)
        cv2.imwrite("processed.png", scale_up)

        # 11. OCR l·∫ßn 1 v·ªõi psm 8
        config1 = '--psm 8 -c tessedit_char_whitelist=0123456789'
        text1 = pytesseract.image_to_string(scale_up, config=config1)
        so1 = ''.join(filter(str.isdigit, text1))

        if so1:
            print(f"[OCR L·∫ßn 1 - psm8]: '{text1.strip()}' ‚û§ K·∫øt qu·∫£: {so1}")
            return so1

        # 12. OCR l·∫ßn 2 v·ªõi psm 7 n·∫øu kh√¥ng nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ ·ªü l·∫ßn 1
        config2 = '--psm 6 -c tessedit_char_whitelist=0123456789'
        text2 = pytesseract.image_to_string(scale_up, config=config2)
        so2 = ''.join(filter(str.isdigit, text2))

        print(f"[OCR L·∫ßn 2 - psm7]: '{text2.strip()}' ‚û§ K·∫øt qu·∫£: {so2}")
        return so2

    except Exception as e:
        print(f"‚ùå L·ªói OCR: {e}")
        return None

def click_thoat_chon_anh_bia(vitri_nut=(1972, 173), delay=0.5, timeout=1, threshold=0.95):
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("thoat_bia_truoc.png", region=vung_nut)

    print(f"Click n√∫t Tho√°t ·∫£nh b√¨a t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p l·∫°i sau khi click
    pyautogui.screenshot("thoat_bia_sau.png", region=vung_nut)

    img1 = cv2.imread("thoat_bia_truoc.png")
    img2 = cv2.imread("thoat_bia_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click n√∫t Tho√°t ·∫£nh b√¨a th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

def click_nut_nhan_them_san_pham(vitri_nut=(2319, 624), delay=0.5, timeout=1, threshold=0.95):
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("them_san_pham_truoc.png", region=vung_nut)

    print(f"Click n√∫t Nh·∫≠n th√™m s·∫£n ph·∫©m t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p l·∫°i sau khi click
    pyautogui.screenshot("them_san_pham_sau.png", region=vung_nut)

    img1 = cv2.imread("them_san_pham_truoc.png")
    img2 = cv2.imread("them_san_pham_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click n√∫t Nh·∫≠n th√™m s·∫£n ph·∫©m th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

def click_nut_them_lien_ket(vitri_nut=(2633, 157), delay=2, timeout=2, threshold=0.97):
    # V√πng n√∫t gi·ªØ nguy√™n
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # üì∏ V√πng ch·ª•p ·∫£nh r·ªông ƒë·ªÉ so s√°nh tr∆∞·ªõc/sau
    vung_so_sanh = (1911, 117, 2686 - 1911, 1687 - 117)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("them_lien_ket_truoc.png", region=vung_so_sanh)
    time.sleep(delay)
    print(f"Click n√∫t Th√™m li√™n k·∫øt t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p ·∫£nh sau khi click
    pyautogui.screenshot("them_lien_ket_sau.png", region=vung_so_sanh)

    img1 = cv2.imread("them_lien_ket_truoc.png")
    img2 = cv2.imread("them_lien_ket_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click n√∫t Th√™m li√™n k·∫øt th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

import pyautogui
import pyperclip
import time

def click_va_dan_link(vitri_o=(1994, 364), doan_text=""):
    print(f"Click t·∫°i {vitri_o} v√† d√°n link...")
    pyperclip.copy(doan_text)          # Copy v√†o clipboard
    pyautogui.moveTo(*vitri_o, duration=0.2)
    pyautogui.click()
    time.sleep(0.5)
    pyautogui.hotkey("ctrl", "v")      # D√°n t·ª´ clipboard
    print("‚úÖ ƒê√£ d√°n link th√†nh c√¥ng.")

def click_nut_nhap(vitri_nut=(2257, 730), delay=0.5, timeout=1, threshold=0.95):
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("nhap_truoc.png", region=vung_nut)

    print(f"Click n√∫t Nh·∫≠p t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p l·∫°i sau khi click
    pyautogui.screenshot("nhap_sau.png", region=vung_nut)

    img1 = cv2.imread("nhap_truoc.png")
    img2 = cv2.imread("nhap_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click n√∫t Nh·∫≠p th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

def click_nut_chon_tat_ca_san_pham(delay=0.5, timeout=1, threshold=0.95):
    time.sleep(1)
    
    toa_do_1 = (1957, 1573)
    toa_do_2 = (2464, 1591)
    vung_nut_2 = (toa_do_2[0] - 50, toa_do_2[1] - 30, 100, 60)

    # Click l·∫ßn 1 (kh√¥ng ki·ªÉm tra)
    print(f"Click l·∫ßn 1 t·∫°i {toa_do_1}")
    pyautogui.moveTo(*toa_do_1, duration=0.2)
    pyautogui.click()
    time.sleep(1)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click l·∫ßn 2
    pyautogui.screenshot("chon_tat_ca_truoc.png", region=vung_nut_2)

    # Click l·∫ßn 2
    print(f"Click l·∫ßn 2 t·∫°i {toa_do_2} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*toa_do_2, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click l·∫ßn 2. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p ·∫£nh sau khi click l·∫ßn 2
    pyautogui.screenshot("chon_tat_ca_sau.png", region=vung_nut_2)

    img1 = cv2.imread("chon_tat_ca_truoc.png")
    img2 = cv2.imread("chon_tat_ca_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click n√∫t Ch·ªçn t·∫•t c·∫£ s·∫£n ph·∫©m th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

def click_va_dan_mo_ta_video(vitri_o=(2235, 294), doan_text=""):
    print(f"Click t·∫°i {vitri_o} v√† them mo ta...")
    pyperclip.copy(doan_text)          # Copy v√†o clipboard
    pyautogui.moveTo(*vitri_o, duration=0.2)
    pyautogui.click()
    time.sleep(0.5)
    pyautogui.hotkey("ctrl", "v")      # D√°n t·ª´ clipboard
    print("‚úÖ ƒê√£ d√°n link th√†nh c√¥ng.")

def click_nut_dong_y_mo_ta(vitri_nut=(2609, 174), delay=0.5, timeout=1, threshold=0.95):
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("dong_y_mo_ta_truoc.png", region=vung_nut)

    print(f"Click n√∫t ƒê·ªìng √Ω nh·∫≠p m√¥ t·∫£ t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p l·∫°i sau khi click
    pyautogui.screenshot("dong_y_mo_ta_sau.png", region=vung_nut)

    img1 = cv2.imread("dong_y_mo_ta_truoc.png")
    img2 = cv2.imread("dong_y_mo_ta_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click n√∫t ƒê·ªìng √Ω nh·∫≠p m√¥ t·∫£ th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n, c√≥ th·ªÉ ch∆∞a ph·∫£n h·ªìi.")
        return False

def click_chon_anh_bia_moi(delay1=0.5, delay2=0.5, timeout=1, threshold=0.95):
    toa_do_1 = (2015, 1487)
    toa_do_2 = (2628, 178)
    vung_nut_2 = (toa_do_2[0] - 50, toa_do_2[1] - 30, 100, 60)

    # Click l·∫ßn 1 (kh√¥ng ki·ªÉm tra)
    print(f"Click l·∫ßn 1 t·∫°i {toa_do_1}")
    time.sleep(delay1)
    pyautogui.moveTo(*toa_do_1, duration=0.2)
    pyautogui.click()

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click l·∫ßn 2
    pyautogui.screenshot("anh_bia_moi_truoc.png", region=vung_nut_2)

    # Click l·∫ßn 2 (c√≥ ki·ªÉm tra)
    print(f"Click l·∫ßn 2 t·∫°i {toa_do_2}")
    time.sleep(delay2)
    pyautogui.moveTo(*toa_do_2, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click l·∫ßn 2. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p ·∫£nh sau khi click
    pyautogui.screenshot("anh_bia_moi_sau.png", region=vung_nut_2)

    img1 = cv2.imread("anh_bia_moi_truoc.png")
    img2 = cv2.imread("anh_bia_moi_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click ch·ªçn ·∫£nh b√¨a m·ªõi th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è Giao di·ªán ch∆∞a thay ƒë·ªïi r√µ r√†ng.")
        return False

def click_nut_dang(vitri_nut=(2357, 1625), delay=0.5, timeout=2, threshold=0.95):
    
    

    time.sleep(1.5)
    
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("dang_truoc.png", region=vung_nut)

    print(f"Click n√∫t ƒêƒÉng t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click. Ch·ªù ph·∫£n h·ªìi...")

    time.sleep(timeout)

    # Ch·ª•p l·∫°i sau khi click
    pyautogui.screenshot("dang_sau.png", region=vung_nut)

    img1 = cv2.imread("dang_truoc.png")
    img2 = cv2.imread("dang_sau.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh_img = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh_img)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng ·∫£nh tr∆∞·ªõc/sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Click n√∫t ƒêƒÉng th√†nh c√¥ng.")
        return True
    else:
        print("‚ö†Ô∏è Giao di·ªán ch∆∞a thay ƒë·ªïi r√µ r√†ng.")
        return False

def click_tro_ve_home(vitri_nut=(1962, 155), delay=0.5):
    print(f"Click n√∫t Tr·ªü v·ªÅ Home t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("‚úÖ ƒê√£ click n√∫t Tr·ªü v·ªÅ Home.")

def thu_lai_click(func, so_lan_thu=2, delay=1):
    for lan in range(so_lan_thu):
        if func():
            return True
        print(f"‚ö†Ô∏è Click th·∫•t b·∫°i l·∫ßn {lan + 1}, th·ª≠ l·∫°i...")
        time.sleep(delay)
    print("‚ùå ƒê√£ th·ª≠ nhi·ªÅu l·∫ßn nh∆∞ng v·∫´n th·∫•t b·∫°i.")
    return False

def click_nut_ban_nhap(vitri_nut=(1986, 1624), delay=0.5, timeout=2, threshold=0.95):
    # X√°c ƒë·ªãnh v√πng ·∫£nh quanh n√∫t
    vung_nut = (vitri_nut[0] - 50, vitri_nut[1] - 30, 100, 60)

    # Ch·ª•p ·∫£nh tr∆∞·ªõc khi click
    pyautogui.screenshot("truoc_click_bannhap.png", region=vung_nut)

    print(f"ƒêang click n√∫t B·∫£n nh√°p t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("ƒê√£ click, ch·ªù giao di·ªán ph·∫£n h·ªìi...")

    time.sleep(timeout)  # Ch·ªù giao di·ªán ph·∫£n h·ªìi

    # Ch·ª•p l·∫°i ·∫£nh sau khi click
    pyautogui.screenshot("sau_click_bannhap.png", region=vung_nut)

    # So s√°nh ·∫£nh tr∆∞·ªõc & sau ƒë·ªÉ ki·ªÉm tra n√∫t c√≥ thay ƒë·ªïi
    img1 = cv2.imread("truoc_click_bannhap.png")
    img2 = cv2.imread("sau_click_bannhap.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng tr∆∞·ªõc & sau khi click: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ N√∫t ƒë√£ bi·∫øn m·∫•t ho·∫∑c thay ƒë·ªïi ‚Üí Click TH√ÄNH C√îNG.")
        return True
    else:
        print("‚ö†Ô∏è N√∫t v·∫´n c√≤n ‚Üí Click c√≥ th·ªÉ KH√îNG th√†nh c√¥ng.")
        return False

def click_nut_back(vitri_nut=(1957, 165), delay=0.5, timeout=2, threshold=0.95):
    # üì∏ V√πng so s√°nh ·∫£nh c·ªë ƒë·ªãnh (kh√¥ng ph·∫£i v√πng quanh n√∫t)
    vung_so_sanh = (1911, 117, 2686 - 1911, 1687 - 117)

    # Ch·ª•p ·∫£nh giao di·ªán tr∆∞·ªõc khi click
    pyautogui.screenshot("giao_dien_truoc_click_back.png", region=vung_so_sanh)

    print(f"üîô ƒêang click n√∫t Back t·∫°i {vitri_nut} sau {delay} gi√¢y...")
    time.sleep(delay)
    pyautogui.moveTo(*vitri_nut, duration=0.2)
    pyautogui.click()
    print("‚è≥ ƒê√£ click, ch·ªù ph·∫£n h·ªìi giao di·ªán...")

    time.sleep(timeout)  # Ch·ªù giao di·ªán ph·∫£n h·ªìi

    # Ch·ª•p l·∫°i ·∫£nh giao di·ªán sau khi click
    pyautogui.screenshot("giao_dien_sau_click_back.png", region=vung_so_sanh)

    # So s√°nh s·ª± thay ƒë·ªïi c·ªßa giao di·ªán
    img1 = cv2.imread("giao_dien_truoc_click_back.png")
    img2 = cv2.imread("giao_dien_sau_click_back.png")

    if img1 is None or img2 is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh so s√°nh.")
        return False

    diff = cv2.absdiff(img1, img2)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    non_zero = cv2.countNonZero(thresh)
    total_pixels = diff.shape[0] * diff.shape[1]
    similarity = 1 - (non_zero / total_pixels)

    print(f"üìä ƒê·ªô t∆∞∆°ng ƒë·ªìng giao di·ªán tr∆∞·ªõc & sau: {similarity:.2f}")

    if similarity < threshold:
        print("‚úÖ Giao di·ªán ƒë√£ thay ƒë·ªïi ‚Üí Click Back TH√ÄNH C√îNG.")
        return True
    else:
        print("‚ö†Ô∏è Giao di·ªán kh√¥ng ƒë·ªïi nhi·ªÅu ‚Üí C√≥ th·ªÉ KH√îNG th√†nh c√¥ng.")
        return False

def dang_1_video():

    time.sleep(2)

    soKhongCoTrongData = False
    
    result = click_nut_dang_video()

    if not result:
        print("‚ùå Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu ƒëƒÉng video.")
        return False

    if not click_nut_thu_vien():
        return False
    
    # üí° Scroll n·∫øu ƒëang x·ª≠ l√Ω video t·ª´ l·∫ßn th·ª© 5 tr·ªü ƒëi
    if so_lan_click_video >= 4:
        pyautogui.scroll(-cuon_chuot_y)
        print(f"üñ±Ô∏è ƒê√£ scroll xu·ªëng {cuon_chuot_y} pixel")

    if not click_chon_video():
        return False

    if not click_nut_tiep_theo():
        return False

    if not click_nut_tiep_theo():
        return False

    if not thu_lai_click(click_nut_chon_anh_bia):
        return False

    time.sleep(1)
    chup_anh_so_video()
    time.sleep(0.2)

    so = nhan_dien_so_tu_anh("anhSoCuaVideo.png")
    if not so:
        print("‚ùå Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c s·ªë.")
        return False
    else:
        print(f"üìå ƒê√£ nh·∫≠n di·ªán ƒë∆∞·ª£c s·ªë: {so}")

        # ‚úÖ D√°n link t∆∞∆°ng ·ª©ng n·∫øu s·ªë c√≥ trong data
        try:
            so_int = int(so)
            if so_int in data:
                link_tuong_ung = data[so_int]
                print(f"üîó D√°n link t∆∞∆°ng ·ª©ng t·ª´ file Excel: {link_tuong_ung}")
            else:
                # Xu ly click luu ban nhap 
                soKhongCoTrongData = True

        except:
            print("‚ö†Ô∏è Kh√¥ng th·ªÉ chuy·ªÉn s·ªë sang int, d√πng linkSP m·∫∑c ƒë·ªãnh.")
            click_va_dan_link(doan_text="linkSP")



    videoDangO = so


    if not click_thoat_chon_anh_bia():
        return False
    
    if soKhongCoTrongData == True:

        if click_nut_ban_nhap():
            print("‚úÖ Da Huy Dang Video vi khong co link trong data.")
            time.sleep(1)
            click_tro_ve_home()

            with open(pathLog, "a", encoding="utf-8") as f:
            
                f.write(f"{videoDangO} Khong Thanh Cong: Khong co link trong data\n")
            
            return True
        
    else:

        if not click_nut_nhan_them_san_pham():
            return False

        if not click_nut_them_lien_ket():
            return False


        # ‚úÖ D√°n link t∆∞∆°ng ·ª©ng n·∫øu s·ªë c√≥ trong data
        try:
            so_int = int(so)
            if so_int in data:
                link_tuong_ung = data[so_int]
                print(f"üîó D√°n link t∆∞∆°ng ·ª©ng t·ª´ file Excel: {link_tuong_ung}")
                click_va_dan_link(doan_text=link_tuong_ung)
            else:
                print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y s·ªë trong file, d√πng linkSP m·∫∑c ƒë·ªãnh.")
                click_va_dan_link(doan_text=linkSP)
        except:
            print("‚ö†Ô∏è Kh√¥ng th·ªÉ chuy·ªÉn s·ªë sang int, d√πng linkSP m·∫∑c ƒë·ªãnh.")
            click_va_dan_link(doan_text="linkSP")

        if not click_nut_nhap():
            return False

        time.sleep(1)

        if not click_nut_chon_tat_ca_san_pham():

            if not click_nut_back():
                return False
            if not click_nut_back():
                return False
            
            if click_nut_ban_nhap():
                print("‚úÖ Da Huy Dang Video vi link khong co san pham.")
                time.sleep(1)
                click_tro_ve_home()

                with open(pathLog, "a", encoding="utf-8") as f:
                
                    f.write(f"{videoDangO} Khong Thanh Cong: khong tim thay san pham tu link\n")
                
                return True
            
            return False


        time.sleep(1)

        click_va_dan_mo_ta_video(doan_text=moTaVideo)

        time.sleep(0.1)

        if not click_nut_dong_y_mo_ta():
            return False

        if not click_nut_chon_anh_bia():
            return False

        if not click_chon_anh_bia_moi():
            return False

        time.sleep(0.5)

        if click_nut_dang():
            print("‚úÖ Video ƒë√£ ƒë∆∞·ª£c ƒëƒÉng.")
            time.sleep(1)
            click_tro_ve_home()

            with open(pathLog, "a", encoding="utf-8") as f:
            
                f.write(f"{videoDangO} thanh cong\n")
            
            return True
        else:
            
            if click_nut_dang():
                print("‚úÖ Video ƒë√£ ƒë∆∞·ª£c ƒëƒÉng.")
                time.sleep(1)
                click_tro_ve_home()

                with open(pathLog, "a", encoding="utf-8") as f:
                
                    f.write(f"{videoDangO} thanh cong\n")
                
                return True
        
            print("‚ùå ƒêƒÉng video th·∫•t b·∫°i.")

            with open("log.txt", "a", encoding="utf-8") as f:
            
            
                f.write(f"{videoDangO} loi\n")
                print("‚õî D·ª´ng ch∆∞∆°ng tr√¨nh do l·ªói trong qu√° tr√¨nh ƒëƒÉng.")

            return False
        


import pandas as pd
import re

def doc_file_va_tra_ve_dict_so_link(duong_dan_file: str, ten_sheet: str = "Sheet1") -> dict:
    """
    ƒê·ªçc file Excel v√† tr·∫£ v·ªÅ dict c√≥ d·∫°ng {s·ªë: link_t∆∞∆°ng_·ª©ng}
    """
    try:
        df = pd.read_excel(duong_dan_file, sheet_name=ten_sheet)
        noi_dung = df.iloc[:, 0].tolist()  # l·∫•y c·ªôt ƒë·∫ßu ti√™n (th∆∞·ªùng l√† 'N·ªôi dung')

        ket_qua = {}
        i = 0
        while i < len(noi_dung) - 1:
            dong = str(noi_dung[i])
            match = re.match(r"(\d+)\.", dong)
            if match:
                so = int(match.group(1))
                link = str(noi_dung[i + 1]).strip()
                if link and link.lower() != "nan":
                    ket_qua[so] = link
                i += 3  # b·ªè qua d√≤ng tr·ªëng
            else:
                i += 1
        return ket_qua

    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc file: {e}")
        return {}

data = doc_file_va_tra_ve_dict_so_link(r"C:\Users\84765\Downloads\DA5_output_final_14.xlsx")
pathLog = r"C:\Users\84765\Desktop\AutoClick\Log\Acc2\log_20.7.txt"

# In k·∫øt qu·∫£
for so, link in data.items():
    print(f"{so} ‚û§ {link}")

# Bi·∫øn to√†n c·ª•c ƒë·ªÉ ch·ªçn video m·ªõi sau m·ªói l·∫ßn ƒëƒÉng
vitri_chon_video = [2535, 1392]
so_lan_click_video = 0
cuon_chuot_y = 0

time.sleep(3)

videoDangO = 10000

so_video_muon_dang = 40  # s·ªë video mu·ªën ƒëƒÉng

for i in range(so_video_muon_dang):
    print(f"\n========================")
    print(f"üé¨ B·∫ÆT ƒê·∫¶U ƒêƒÇNG VIDEO TH·ª® {i+1}")
    print(f"========================")
    if not dang_1_video():
        print("‚õî D·ª´ng ch∆∞∆°ng tr√¨nh do l·ªói trong qu√° tr√¨nh ƒëƒÉng.")
        break
